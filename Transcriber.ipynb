{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d0462ca-1b56-423e-bcca-40427a39a625",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matte\\AppData\\Local\\Temp\\ipykernel_35792\\1303325474.py:20: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  inputs=gr.inputs.Textbox(label=\"Enter YouTube URL:\"),\n",
      "C:\\Users\\matte\\AppData\\Local\\Temp\\ipykernel_35792\\1303325474.py:20: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  inputs=gr.inputs.Textbox(label=\"Enter YouTube URL:\"),\n",
      "C:\\Users\\matte\\AppData\\Local\\Temp\\ipykernel_35792\\1303325474.py:20: GradioDeprecationWarning: `numeric` parameter is deprecated, and it has no effect\n",
      "  inputs=gr.inputs.Textbox(label=\"Enter YouTube URL:\"),\n",
      "C:\\Users\\matte\\AppData\\Local\\Temp\\ipykernel_35792\\1303325474.py:21: GradioDeprecationWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  outputs=gr.outputs.Textbox(label=\"Status:\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7871\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7871/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# download clip to a download folder\n",
    "import os\n",
    "from pytube import YouTube\n",
    "import gradio as gr\n",
    "def download_video(url):\n",
    "    try:\n",
    "        yt = YouTube(url)\n",
    "        video = yt.streams.get_highest_resolution()\n",
    "        output_directory = './downloads'  # Note: Using './' to specify a relative path\n",
    "        if not os.path.exists(output_directory):\n",
    "            os.makedirs(output_directory)\n",
    "        video.download(output_path=output_directory)\n",
    "        return f\"Video '{yt.title}' has been downloaded successfully.\"\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=download_video, \n",
    "    inputs=gr.inputs.Textbox(label=\"Enter YouTube URL:\"),\n",
    "    outputs=gr.outputs.Textbox(label=\"Status:\")\n",
    ")\n",
    "\n",
    "# Launch the interface and capture the URL\n",
    "url = interface.launch()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c670f37-b225-4a5b-a7c9-cf560c02da66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in converted_audio//Kamina - Believe in me who believes in you.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEBVTT\n",
      "\n",
      "00:00:00.000 --> 00:00:02.000\n",
      "いいかシモン、忘れんな\n",
      "\n",
      "00:00:02.000 --> 00:00:04.000\n",
      "お前を信じろ\n",
      "\n",
      "00:00:04.000 --> 00:00:06.000\n",
      "俺が信じるお前でもない\n",
      "\n",
      "00:00:06.000 --> 00:00:08.000\n",
      "お前が信じる俺でもない\n",
      "\n",
      "00:00:08.000 --> 00:00:10.000\n",
      "お前が信じる\n",
      "\n",
      "00:00:10.000 --> 00:00:12.000\n",
      "お前を信じろ\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# transcribe clip\n",
    "## Convert clip to audio\n",
    "from moviepy.editor import VideoFileClip\n",
    "video_path = 'downloads/Kamina - Believe in me who believes in you.mp4'\n",
    "video = VideoFileClip(video_path)\n",
    "audio_path = f'converted_audio/{video_path[9:-4]}.wav' # removes .mp4 file extension\n",
    "video.audio.write_audiofile(audio_path) \n",
    "\n",
    "## Transcribe audio\n",
    "### Note: Thinking to run a loop to stich together overlapping segments so that transcript is clean. use prompt argument and a way to reference last x-amount of strings of transcript as its being written. \n",
    "\n",
    "### raw_transcript as json\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "audio_file = open(audio_path, 'rb') # rb is read binary, used to open non-txt files like audio or images\n",
    "v1_transcript = openai.Audio.transcribe(\n",
    "    file=audio_file,\n",
    "    model=\"whisper-1\",\n",
    "    response_format='json',\n",
    "    temperature=0.2\n",
    "    )\n",
    "\n",
    "### raw_transcript as vtt\n",
    "audio_file = open(audio_path, 'rb') # rb is read binary, used to open non-txt files like audio or images\n",
    "v1_transcript_vtt = openai.Audio.transcribe(\n",
    "    file=audio_file,\n",
    "    model=\"whisper-1\",\n",
    "    response_format='vtt',\n",
    "    temperature=0.2\n",
    "    )\n",
    "\n",
    "\n",
    "# ### ask chatgpt what language this trancript is in (give it the first 1000 strs) should return a one word string\n",
    "# # \n",
    "# messages=[\n",
    "#     {'role':'system', 'content':'''You are a robot that is specifically designed to figure out what language a transcript is in. \n",
    "#     When given a transcript, ONLY return the ISO-639-1 language code. Take your time and think this through.'''},\n",
    "#     {'role': 'user', 'content': 'je suis américain'},\n",
    "#     {'role': 'assistant', 'content': 'fr'},\n",
    "#     {'role': 'user', 'content': v1_transcript['text']}\n",
    "# ]\n",
    "# response = openai.ChatCompletion.create(\n",
    "#     model='gpt-3.5-turbo-0613',\n",
    "#     messages=messages,\n",
    "#     temperature=0\n",
    "# )\n",
    "# language = response['choices'][0]['message']['content']\n",
    "# print(language)\n",
    "# ### retranscribe in correct language to improve accuracy\n",
    "# audio_file = open(audio_path, 'rb') # rb is read binary, used to open non-txt files like audio or images\n",
    "# v2_transcript = openai.Audio.transcribe(\n",
    "#     file=audio_file,\n",
    "#     model=\"whisper-1\",\n",
    "#     response_format='json',\n",
    "#     temperature=0.2\n",
    "#     language=language\n",
    "#     )\n",
    "# ### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb5b58fb-214e-4e6a-a90a-0eddbfd9a4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"\\u3044\\u3044\\u304b\\u30b7\\u30e2\\u30f3 \\u5fd8\\u308c\\u3093\\u306a \\u304a\\u524d\\u3092\\u4fe1\\u3058\\u308d \\u4ffa\\u304c\\u4fe1\\u3058\\u308b\\u304a\\u524d\\u3067\\u3082\\u306a\\u3044 \\u304a\\u524d\\u304c\\u4fe1\\u3058\\u308b\\u4ffa\\u3067\\u3082\\u306a\\u3044 \\u304a\\u524d\\u304c\\u4fe1\\u3058\\u308b\\u304a\\u524d\\u3092\\u4fe1\\u3058\\u308d\"\n",
      "}\n",
      "\n",
      "WEBVTT\n",
      "\n",
      "00:00:00.000 --> 00:00:02.000\n",
      "いいかシモン、忘れんな\n",
      "\n",
      "00:00:02.000 --> 00:00:04.000\n",
      "お前を信じろ\n",
      "\n",
      "00:00:04.000 --> 00:00:06.000\n",
      "俺が信じるお前でもない\n",
      "\n",
      "00:00:06.000 --> 00:00:08.000\n",
      "お前が信じる俺でもない\n",
      "\n",
      "00:00:08.000 --> 00:00:10.000\n",
      "お前が信じる\n",
      "\n",
      "00:00:10.000 --> 00:00:12.000\n",
      "お前を信じろ\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# save transcript as jhson and or vtt file with timestamps\n",
    "import json\n",
    "transcript_path = f'transcript/{audio_path[15:-4]}.json'\n",
    "with open(transcript_path, 'w') as json_file:\n",
    "    json.dump(v1_transcript, json_file)\n",
    "\n",
    "transcript_path = f'transcript/{audio_path[15:-4]}.vtt'\n",
    "with open(transcript_path, 'w',encoding='utf-8') as vtt_file:\n",
    "    vtt_file.write(v1_transcript_vtt)\n",
    "    \n",
    "print(v1_transcript)\n",
    "print('')\n",
    "print(v1_transcript_vtt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1b3519-3cf3-4d66-b391-4ee2b252516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass to teacher the v1_transcript (json object) or load the object"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
